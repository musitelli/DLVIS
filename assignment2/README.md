Basado en Assignment 2 de Stanford cs231n.
Contenido
Q1: Redes Neuronales Totalmente Conectadas (30 puntos)
Q2: Batch Normalization (20 puntos)
Q3: Dropout (10 puntos)
Q4: Redes Convolucionales (40 puntos )
Q5: PyTorch en CIFAR-10 (OPCIONAL: 10 puntos extra)
Entrega de archivos
Objetivos
En este entregable se trabajará sobre la implementación de backprogation, y el entrenamiento de redes neuronales totalmente conectadas y redes neuronales convolucionales. Los objetivos de esta tarea son los siguientes:

Entender las Redes Neuronales y como se organizan las arquitecturas por capas.
Entender y ser capaz de implementar el algoritmo de Backpropagation (vectorizado)
Implementar varias técnicas de actualización para optimizar las Redes Neuronales,
Entender e implementar Batch Normalization para el entrenamiento de redes profundas.
Implementar Dropout como método de regularización.
Entender la arquitectura de las Redes Neuronales Convolucionales y practicar entrenandolas.
Ganar experiencia en una de las principales librerías de aprendizaje profundo, PyTorch. (Opcional)

Modalidad de trabajo
Completar cada notebook siguiendo el orden especificado más abajo. Leer con atención la propuesta de cada uno y las recomendaciones que se sugieren. Las preguntas están escritas en inglés pero se aceptan respuestas en español.


Q1: Redese Neuronales Totalmente Conectadas (30 puntos)
El notebook FullyConnectedNets.ipynb te permitirá implementar redes totalmente conectadas de profundidad arbitraria. Para optimizar estos modelos implementarás varias técnicas de actualización conocidas.

Q2: Batch Normalization (20 puntos)
El notebook BatchNormalization.ipynb te ayudará a entender Batch Normalization, y lo usarás para entrenar redes profundas totalmente conectadas.

Q3: Dropout (10 puntos)
El notebook Droput.ipynb te ayudará a a implementar Dropout y explorar su efecto en la generalización del modelo.

Q4: Redes Neuronales Convolucionales (40 puntos)
En el notebook ConvolutionalNetworks.ipynb implementarás varias capas nuevas que son comúnmente utilizadas en redes neuronales convolucionales.

Q5: PyTorch en CIFAR-10 (10 puntos extra)
Esta parte es opcional pero fuertemente recomendada. En esta parte, trabajarás en PyTorch, una de las populares y poderosas librerías de aprendizaje profundo.  Abre el notebook PyTorch.ipynb. Allí, aprenderás como funcionan las librerías, culminando en el entrenamiento de una red convolucional de tu diseño en CIFAR-10, buscando lograr la mejor performance posible.


Instrucciones de Entrega
Importante. Asegurarse que los notebooks entregados hayan sido ejecutados y que las salidas de las celdas y tus respuestas a las preguntas sean visibles.
Abrir y ejecutar el notebook collect_submission.ipynb. Este devolverá:
Un archivo a2_code_submission.zip con todos los archivos de código (.py e .ipynb). 
Un archivo de todos los notebooks con sus celdas y las salidas de éstas.
Por último verificar que estos archivos estén correctos y subirlos a esta tarea.